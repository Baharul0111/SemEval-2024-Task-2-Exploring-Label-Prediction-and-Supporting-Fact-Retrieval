{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WJxJZ0bTUsTM",
        "outputId": "081a57b7-57b6-43e8-881b-d4c7c76e6ef5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting Rouge\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from Rouge) (1.16.0)\n",
            "Installing collected packages: Rouge\n",
            "Successfully installed Rouge-1.0.1\n"
          ]
        }
      ],
      "source": [
        "!pip install Rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Bi82sjodNzWe"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import gensim\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from rouge import Rouge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4t_34FiVO29m",
        "outputId": "ead0231e-caa4-43d4-85c6-fb320f4cace1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "6KKIMC1TO9yp"
      },
      "outputs": [],
      "source": [
        "pretrained_model_path = '/content/drive/My Drive/BioWordVec/bio_embedding_intrinsic'\n",
        "pretrained_model = gensim.models.KeyedVectors.load_word2vec_format(pretrained_model_path, binary=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "k5Rd0OMAPJ33"
      },
      "outputs": [],
      "source": [
        "def preprocess_text(text):\n",
        "    tokens = text.split()\n",
        "    tokens = [word for word in tokens if word in pretrained_model.key_to_index]\n",
        "    return tokens\n",
        "\n",
        "def text_to_sequence(text, tokenizer, max_len):\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    return pad_sequences(seq, maxlen=max_len, padding='post')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Ji2fPNWZPdoE"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('merged_dataset_new.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_roIqZkBPjw1"
      },
      "outputs": [],
      "source": [
        "df['Output'] = \"Primary Evidence: \" +df['Primary_evidence_index'].fillna('') + ' ' \" Secondary Evidences: \"+ df['Secondary_evidence_index'].fillna('')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "yacIEgCoQN7g"
      },
      "outputs": [],
      "source": [
        "all_texts = df['Statement'].tolist() + df['Reference_data'].tolist() + df['Output'].tolist()\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(all_texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "0y03G1cXPsme"
      },
      "outputs": [],
      "source": [
        "max_len = max([len(text.split()) for text in all_texts])\n",
        "vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = pretrained_model.vector_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "9udmJ2QEPzab"
      },
      "outputs": [],
      "source": [
        "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
        "for word, i in tokenizer.word_index.items():\n",
        "    if word in pretrained_model.key_to_index:\n",
        "        embedding_matrix[i] = pretrained_model[word]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WgQsxWCfP6Dl"
      },
      "outputs": [],
      "source": [
        "def text_to_sequence(text, tokenizer, max_len):\n",
        "    seq = tokenizer.texts_to_sequences([text])\n",
        "    return pad_sequences(seq, maxlen=max_len, padding='post')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "P_pE21gwQJcx"
      },
      "outputs": [],
      "source": [
        "df['Statement_seq'] = df['Statement'].apply(lambda x: text_to_sequence(x, tokenizer, max_len))\n",
        "df['Reference_data_seq'] = df['Reference_data'].apply(lambda x: text_to_sequence(x, tokenizer, max_len))\n",
        "df['Output_seq'] = df['Output'].apply(lambda x: text_to_sequence(x, tokenizer, max_len))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "DPogd7LLV-5s"
      },
      "outputs": [],
      "source": [
        "X = np.array([np.hstack([s, r]) for s, r in zip(df['Statement_seq'].values.tolist(), df['Reference_data_seq'].values.tolist())])\n",
        "y = df['Output'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "DUt92f6DQgPe"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "aUpnuh80RlGa"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "zWOZ0Ug6RtR9"
      },
      "outputs": [],
      "source": [
        "y_train_seq = np.array([text_to_sequence(text, tokenizer, max_len) for text in y_train])\n",
        "y_test_seq = np.array([text_to_sequence(text, tokenizer, max_len) for text in y_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZxHwpoX_SC1n"
      },
      "outputs": [],
      "source": [
        "y_train_seq_cat = np.array([to_categorical(seq, num_classes=vocab_size) for seq in y_train_seq])\n",
        "y_test_seq_cat = np.array([to_categorical(seq, num_classes=vocab_size) for seq in y_test_seq])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66WMM4e4TTFJ"
      },
      "outputs": [],
      "source": [
        "### System Crashed After using all available RAM"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
